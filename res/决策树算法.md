# 决策树(Decision Tree)

从树根节点到每一个叶节点都是一个决策，叶节点表示决策的结果(True/False)

从数据集中学习到**最优**的决策树有下面的几种方法

## ID3算法

利用最大信息增益(Information Gain)的方法，每次决定子节点的时候选择能够使信息增益最大的属性(attribute)，也就是能够使熵减最大的属性，该算法属于**贪心**算法。

### 缺点

* 在选择子节点时偏向于取值数目较多的属性，且只能处理离散属性。
* 过拟合(overfitting)问题，可通过设定新的优化目标：conplexity(f(x)) + accuracy(f(x))来解决，其中complexity(f(x))表示决策树的复杂程度（一般用Minimum Description Length来描述），accuracy(f(x))，表示决策树的准确度，新的优化目标目的是在二者之间找到平衡点（解决过拟合问题的一般性思路）。

## C4.5算法

和ID3算法类似，只不过将信息增益改为**信息增益率**，能够解决之前提到的选择子节点时偏向于取值数目较多较多的属性问题。

信息增益率的定义：

## CART算法
